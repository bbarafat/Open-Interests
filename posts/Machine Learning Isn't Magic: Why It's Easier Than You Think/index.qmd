---
title: "Machine Learning Isn't Magic: Why It's Easier Than You Think"
image: ml-unsplash.jpg
author: "Bright A. Bello"
date: "2026-01-13"
categories: [news]
toc: true
toc-depth: 3
toc-title: "On this page"
---

![Photo by <a href="https://unsplash.com/@ikukevk?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Kevin Ku</a> on <a href="https://unsplash.com/photos/closeup-photo-of-eyeglasses-w7ZyuGYNpRQ?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>](ml-unsplash.jpg)

# Introduction

A lot of people in the world today have heard about machine learning, most have heard about
AI, and everyone has interacted with machine learning in one way or the other. It is sometimes
referred to as AI’s stepchild, AI’s lesser known twin and even AI’s second banana. 


Despite its popularity, most people do not know exactly what it is. Some may think its some kind of
wizardry or witchcraft and a lot of people will assume its a field too complex to comprehend.
Today, we will unmask this creature and expose its secrets for all to see.

## Definition

Formally, and boringly;

 “Machine learning is the subset of artificial intelligence (AI) focused on algorithms that can “learn” the
patterns of training data and, subsequently, make accurate inferences about new data. This pattern recognition ability enables machine learning models to make decisions or predictions without explicit, hard-coded instructions.”.

Simply put however, machine learning refers to when machines (computers) learn stuff (I’m only slightly
joking).

## Brief History

Lets start from the beginning, what is machine learning and where did it come from?

Lets go back in time a little bit. You see, what happened in 1943 was that neuroscientist’s
Walter Pitts and Warren McCulloch devised a mathematical model of a neural network to
create algorithms that mimic human thought processes. 

Other pioneers like Alan Turing came to the fore in the 1950’s and 1960’s and bit by bit the AI and machine learning landscape was
crafted. 

You remember the definition from the section above? This is at its heart what machine learning is. How does it do this though? 
In comes statistics (Yes you read that right, its the same statistics you didn’t like in high school). 

Machine learning can be thought of as the master statistician. 
it takes data, a lot of data, and through complex training processes and strict protocols, learns the underlying patterns of the dataset, and then uses this knowledge to build a model and make predictions or clustering (Don't panic, we'll come to this later) depending on the flavor of model we are developing. All of this involves statistical concepts, calculus and linear algebra.

# Types Of Machine Learning

![Photo by ChatGPT 5.2](ml-types.png)

Machine learning comes in three main flavors;

## Supervised Learning
Supervised learning is a machine learning flavor that works with labeled data. 

Think of a table where each column represents features, and one column is our target variable of interest.
An example would be a data of houses where each column is an attribute of the house, such
as number of bedrooms, square footage, etc, and the target variable is price, our variable of
interest. 

Our model would learn patterns from the attributes in order to predict the price of
a house given certain characteristics. It is called supervised because it has clear correct answers
to guide its learning. 

In supervised learning, we either aim to predict continuous values like
prices (regression), or to classify (predict whether something is an apple or banana based on
features).


## Unsupervised Learning

This is a machine learning flavor that works with unlabeled data unlike its supervised counterpart.

This version does not have clearly correct labelled answers to work with. 
Given a dataset, it finds hidden patterns and structures in unlabeled data without human guidance. It typically
clusters the data into blocks based on patterns it discovers and believes to be important.


## Reinforcement Learning

This is a type of machine learning flavor where an agent (a bot/machine) learns to make decisions
by interacting with an environment, taking actions, and receiving rewards or penalties
(feedback) to discover an optimal strategy (policy) for maximizing cumulative rewards over
time. Much like trial-and-error learning. 

It excels at complex problems like game playing (Chess, Go) or robotics, training systems to learn from experience without explicit programming, unlike supervised learning which uses labeled data.

Whew, that was a lot of words. What does it mean though?

Let's look at an example. Think about teaching a bot how to play chess. Your environment is the chessboard that the bot has to learn to navigate. We need to teach the bot the basic rules, and some strategies.

For each move the bot gets right, we reward it, and punish it for wrong moves. When it receives a reward or punishment, it updates the policy (In this case, this refers to the best moves for each position, or what to avoid).

Over time, the bot learns context, and is able to decide what the best move for each situation is based on the pieces on the board, and the opponents' last move.


# Training Process

So far so good right?

Now lets see how the learning is actually done;


![Photo by <a href="https://media.geeksforgeeks.org/wp-content/uploads/20250110153147721466/Machine-Learning-Techniques.webp"> geeks for geeks </a> ](workflow.png)


## Data Gathering And Cleaning (Preprocessing)

Raw data is gathered either from first hand sources (surveys etc) or second hand datasets that are publicly availabe. 

This data is cleaned and made ready for modelling. 

Cleaning data is usually the first stage of the modelling process and can be quite intense. It requires knowledge of the data and its collection process as well as an understanding of the data available in each column (feature).

This cleaning could involve handling null or incorrect values, outliers and distributions of each feature, etc.

This is usually referred to as preprocessing.

## Feature Engineering And Exploratory Data Analysis (EDA)

After the preprocessing is complete, the features are examined and re-engineered if need be. Re-engineering in this context refers to creating new features based on the features we already have. 

Examining (EDA) involves the creation of charts and summary statistics to investigate probable patterns and statistical distributions of the data and its features. 

This stage typically requires some domain knowledge on the topic being modelled, as well as knowledge of statistics.

Feature Engineering happens after the EDA stage is complete. The information we gather from examining the data, along with any domain knowledge we may have, will inform our choice of transformation and new feature creation.

In some Machine Learning Literature, this step is sometimes lumped in with preprocessing.

## Model Selection

After all this glorious work is done, we do the shiny stuff. We choose a model.

Depending on the task at hand and the data we have, we make informed decisions about our model using our knowledge of statistics.

There is a wide range of models to choose from, including Linear Regression, Logistic regression, XGBoost, etc.

We usually have a few models we want to try out to see which one fits the data best. We choose these models, and using a cross validation strategy (We basically select different subsets of the data and train the model on all the subsets), we train all the selected models, then we choose the best performing model from among them all.

We can then perform some diagnosis to investigate how well our model is performing.

## Deploying

When we get a new car, we don't park it safely in our garage at home. We take it out for the whole neighborhood to look at. This is the same concept we employ in machine learning. 

After the glorious workflow above is complete, we make it available for everyone to use, also known as deploying the model. There are various ways to do this which I won't go into, but this is typically the final stage in the process.


## Conclusion

And just like that, the machine learning process is complete. Easy enough to understand right?

As with all skills, in order to actually be good at machine learning, you need to get your hands
dirty. 

Building the models themselves will involve more detailed learning and domain knowledge than mentioned in this write up. 
This write up is meant to show that on a high-level, machine learning is conceptually very easy to understand.

Now when your granny asks you, you can explain to her what the fuss is all about.